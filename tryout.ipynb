{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc68c35",
   "metadata": {},
   "source": [
    "# Ax optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5fe121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 06-15 07:14:04] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x1. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 06-15 07:14:04] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x2. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 06-15 07:14:04] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='x1', parameter_type=FLOAT, range=[-10.0, 10.0]), RangeParameter(name='x2', parameter_type=FLOAT, range=[-10.0, 10.0])], parameter_constraints=[]).\n",
      "[INFO 06-15 07:14:04] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 06-15 07:14:04] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 06-15 07:14:04] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 06-15 07:14:05] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 06-15 07:14:05] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 06-15 07:14:05] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 06-15 07:14:05] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 06-15 07:14:06] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 06-15 07:14:06] ax.service.managed_loop: Running optimization trial 15...\n",
      "[INFO 06-15 07:14:07] ax.service.managed_loop: Running optimization trial 16...\n",
      "[INFO 06-15 07:14:07] ax.service.managed_loop: Running optimization trial 17...\n",
      "[INFO 06-15 07:14:08] ax.service.managed_loop: Running optimization trial 18...\n",
      "[INFO 06-15 07:14:08] ax.service.managed_loop: Running optimization trial 19...\n",
      "[INFO 06-15 07:14:09] ax.service.managed_loop: Running optimization trial 20...\n"
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "best_parameters, best_values, experiment, model = optimize(\n",
    "        parameters=[\n",
    "          {\n",
    "            \"name\": \"x1\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"x2\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "        ],\n",
    "        # Booth function\n",
    "        evaluation_function=lambda p: (p[\"x1\"] + 2*p[\"x2\"] - 7)**2 + (2*p[\"x1\"] + p[\"x2\"] - 5)**2,\n",
    "        minimize=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebbeadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': 1.0499033778313702, 'x2': 3.0411949204629796}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce601367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 06-15 07:12:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x1. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 06-15 07:12:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x2. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 06-15 07:12:56] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='x1', parameter_type=FLOAT, range=[-10.0, 10.0]), RangeParameter(name='x2', parameter_type=FLOAT, range=[-10.0, 10.0])], parameter_constraints=[]).\n",
      "[INFO 06-15 07:12:56] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 06-15 07:12:56] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 06-15 07:12:56] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 06-15 07:12:57] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 06-15 07:12:57] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 06-15 07:12:57] ax.service.managed_loop: Running optimization trial 9...\n",
      "/home/mohan/anaconda3/envs/bt/lib/python3.9/site-packages/gpytorch/utils/cholesky.py:38: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "[INFO 06-15 07:12:57] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 06-15 07:12:58] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 06-15 07:12:58] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 06-15 07:12:58] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 06-15 07:12:58] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 06-15 07:12:59] ax.service.managed_loop: Running optimization trial 15...\n",
      "[INFO 06-15 07:12:59] ax.service.managed_loop: Running optimization trial 16...\n",
      "[INFO 06-15 07:12:59] ax.service.managed_loop: Running optimization trial 17...\n",
      "[INFO 06-15 07:13:00] ax.service.managed_loop: Running optimization trial 18...\n",
      "[INFO 06-15 07:13:00] ax.service.managed_loop: Running optimization trial 19...\n",
      "[INFO 06-15 07:13:00] ax.service.managed_loop: Running optimization trial 20...\n"
     ]
    }
   ],
   "source": [
    "best_parameters, best_values, experiment, model = optimize(\n",
    "        parameters=[\n",
    "          {\n",
    "            \"name\": \"x1\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"x2\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "        ],\n",
    "        # Booth function\n",
    "        evaluation_function=lambda p: (p[\"x1\"])**2 + (p[\"x2\"] - 5)**2,\n",
    "        minimize=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05458166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x1': 10.0, 'x2': -10.0},\n",
       " ({'objective': 324.9381930848465},\n",
       "  {'objective': {'objective': 0.8859988544696163}}),\n",
       " Experiment(None),\n",
       " <ax.modelbridge.torch.TorchModelBridge at 0x7f663ff22cd0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters, best_values, experiment, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9230793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple, Type\n",
    "\n",
    "# Ax wrappers for BoTorch components\n",
    "from ax.models.torch.botorch_modular.model import BoTorchModel\n",
    "from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
    "from ax.models.torch.botorch_modular.list_surrogate import ListSurrogate\n",
    "from ax.models.torch.botorch_modular.acquisition import Acquisition\n",
    "\n",
    "# Ax data tranformation layer\n",
    "from ax.modelbridge.torch import TorchModelBridge\n",
    "from ax.modelbridge.registry import Cont_X_trans, Y_trans, Models\n",
    "\n",
    "# Experiment examination utilities\n",
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "# Test Ax objects\n",
    "from ax.utils.testing.core_stubs import (\n",
    "    get_branin_experiment, \n",
    "    get_branin_data, \n",
    "    get_branin_experiment_with_multi_objective,\n",
    "    get_branin_data_multi_objective,\n",
    ")\n",
    "\n",
    "# BoTorch components\n",
    "from botorch.models.model import Model\n",
    "from botorch.models.gp_regression import FixedNoiseGP, SingleTaskGP\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2bbde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 06-15 07:00:31] ax.core.experiment: The is_test flag has been set to True. This flag is meant purely for development and integration testing purposes. If you are running a live experiment, please set this flag to False\n"
     ]
    }
   ],
   "source": [
    "experiment = get_branin_experiment(with_trial=True)\n",
    "data = get_branin_data(trials=[experiment.trials[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd149fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 06-15 07:00:32] ax.modelbridge.transforms.standardize_y: Outcome branin is constant, within tolerance.\n"
     ]
    }
   ],
   "source": [
    "model_bridge_with_GPEI = Models.BOTORCH_MODULAR(\n",
    "    experiment=experiment,\n",
    "    data=data,\n",
    "    surrogate=Surrogate(SingleTaskGP),  # Optional, will use default if unspecified\n",
    "    botorch_acqf_class=qNoisyExpectedImprovement,  # Optional, will use default if unspecified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a0c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm(parameters={'x1': 10.0, 'x2': 0.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_run = model_bridge_with_GPEI.gen(n=1)\n",
    "generator_run.arms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a040b",
   "metadata": {},
   "source": [
    "# scipy optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0701c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   direc: array([[1., 0.],\n",
       "       [0., 1.]])\n",
       "     fun: 4.930380657631324e-32\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 36\n",
       "     nit: 2\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1. , 2.5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "res = minimize(fun, (2, 0), method='powell')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46ee6b",
   "metadata": {},
   "source": [
    "# scipy optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "# bounds = optimize.Bounds(lb=-1000., ub=1000.)\n",
    "# res = optimize.minimize(fun=func, x0=np.array([1]), method='Powell', bounds=((-1000., 1000.)))\n",
    "# print(res)\n",
    "\n",
    "\n",
    "fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "# res = optimize.minimize(fun, (2, 0), method='TNC', tol=1e-10)\n",
    "# print(res)\n",
    "bnds = ((0.25, 100), (0, 2.0))\n",
    "res = optimize.minimize(fun=fun, x0=(2, 0), method='Powell', bounds=bnds)\n",
    "print(res.x)\n",
    "\n",
    "fun = lambda x: (x[0] - 1)**2\n",
    "bnds = ((0.25, 100),)\n",
    "res = optimize.minimize(fun=fun, x0=(2,), method='Powell', bounds=bnds)\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d2d5d",
   "metadata": {},
   "source": [
    "# sklearn random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78e295b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('gb', GradientBoostingRegressor(random_state=1)),\n",
       "                            ('rf',\n",
       "                             RandomForestRegressor(n_estimators=10,\n",
       "                                                   random_state=1)),\n",
       "                            ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Train classifiers\n",
    "reg1 = GradientBoostingRegressor(random_state=1)\n",
    "reg2 = RandomForestRegressor(n_estimators= 10, random_state=1)\n",
    "reg3 = LinearRegression()\n",
    "\n",
    "reg1.fit(X, y)\n",
    "reg2.fit(X, y)\n",
    "reg3.fit(X, y)\n",
    "\n",
    "ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n",
    "ereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c85dbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e787984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158.4,  80.1, 163.3, 197.9, 117.7, 105.1, 105.8,  87.1, 117.9,\n",
       "       238.9, 106.8,  94.2, 149.5, 177.7, 113.7, 178.4, 207.7, 153. ,\n",
       "        92.6, 145.5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = X[:20]\n",
    "pred2 = reg2.predict(xt)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e5742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa4b50316a0dd11958090de8b1023e6914bc06ba958c2ee85f17379513c9c8a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
